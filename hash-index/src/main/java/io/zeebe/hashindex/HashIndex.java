/*
 * Copyright Â© 2017 camunda services GmbH (info@camunda.com)
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package io.zeebe.hashindex;

import static io.zeebe.hashindex.HashIndexDescriptor.BLOCK_DATA_OFFSET;

import java.lang.reflect.ParameterizedType;
import java.util.concurrent.atomic.AtomicBoolean;

import org.agrona.BitUtil;
import org.agrona.CloseHelper;
import org.slf4j.Logger;

/**
 * Simple index data structure using extensible hashing.
 * Data structure is not threadsafe.
 *
 * The index size should be a power of two. If it is not a power of two the next power
 * of two is used. The max index size is {@link HashIndex#MAX_INDEX_SIZE} as the index stores
 * long addresses and this is the maximum number of entries which can be addressed with index keys
 * generated by {@link IndexKeyHandler#keyHashCode}.
 *
 */
public class HashIndex<K extends IndexKeyHandler, V extends IndexValueHandler>
{
    private static final int KEY_HANDLER_IDX = 0;
    private static final int VALUE_HANDLER_IDX = 1;
    private static final String FINALIZER_WARNING = "HashIndex is being garbage collected but is not closed.\n" +
        "This means that the object is being de-referenced but the close() method has not been called.\n" +
        "HashIndex allocates memory off the heap which is not reclaimed unless close() is invoked.\n";

    public static final Logger LOG = Loggers.HASH_INDEX_LOGGER;

    /**
     * The maximum index size is 2^27, because it is the last power of two which fits into an integer after multiply with SIZE_OF_LONG (8 bytes).
     * <p>
     * The index size have to be multiplied with SIZE_OF_LONG to calculated the size of the index buffer,
     * which have to be allocated to store all indices. The indices, which are stored in the index buffer, are longs.
     */
    public static final int MAX_INDEX_SIZE = 1 << 27;

    /**
     * The optimal bucket count regarding to performance and memory usage.
     * Was determined with help of some benchmarks see {@link io.zeebe.hashindex.benchmarks.HashIndexDetermineSizesBenchmark}.
     */
    public static final int OPTIMAL_BUCKET_COUNT = 16;

    /**
     * The optimal index size was calculated with regard to the {@link #OPTIMAL_BUCKET_COUNT}
     * and a requirement to store 100_000_000 entries in the index.
     */
    public static final int OPTIMAL_INDEX_SIZE = 1 << 23;

    protected final K keyHandler;
    protected final K splitKeyHandler;
    protected final V valueHandler;

    protected final HashIndexBuffer indexBuffer;
    protected final HashIndexDataBuffer dataBuffer;

    protected final int indexSize;
    protected final int mask;

    protected final AtomicBoolean isClosed = new AtomicBoolean(false);

    /**
     * Creates an hash index object.
     *
     * <p>
     * The index can store `X` entries, which is at maximum equal to `indexSize * maxBlockLength`.
     * For each bucket a buffer will be allocated, with the size of `maxBlockLength * keyLength + {@link HashIndexDescriptor#BLOCK_BUFFER_HEADER_LENGTH}`.
     * </p>
     *
     * <p>
     * Note: it could happen that some hashes modulo the index size generate the same bucket id, which means
     * some buckets can be filled more than other. This will end in a filled index, since one bucket is filled and can't
     * be split again. In that case less then X entries can be stored in the index.
     * To avoid this the implementation of the `IndexKeyHandler` have to provide a good one way function.
     * </p>
     *
     * <b>Example:</b>
     * <pre>
     * Index with index size 6 and maxBlockLength of 3 * (VAL len + KEY len)
     * KeyTable                Buckets:
     * [bucket0]      ->     [ [KEY | VAL] | [KEY | VAL] | [KEY | VAL] ]
     * [bucket1]      ->     [ [KEY | VAL] | [KEY | VAL] | [KEY | VAL] ]
     * [bucket2]      ->     [ [KEY | VAL] | [KEY | VAL] | [KEY | VAL] ]
     * [bucket3]      ->     [ [KEY | VAL] | [KEY | VAL] | [KEY | VAL] ]
     * [bucket4]      ->     [ [KEY | VAL] | [KEY | VAL] | [KEY | VAL] ]
     * [bucket5]      ->     [ [KEY | VAL] | [KEY | VAL] | [KEY | VAL] ]
     * </pre>
     *
     * @param indexSize is the count of buckets, which should been used by the hash index
     * @param maxBlockLength is the count of entries, which should fit into one bucket, already multiplied with the value and key size
     * @param keyLength the length of the stored keys
     */
    public HashIndex(
            int indexSize,
            int maxBlockLength,
            int keyLength)
    {
        this.indexSize = ensureIndexSizeIsPowerOfTwo(indexSize);
        this.mask = this.indexSize - 1;

        this.keyHandler = createKeyHandlerInstance(keyLength);
        this.splitKeyHandler = createKeyHandlerInstance(keyLength);
        this.valueHandler = createInstance(VALUE_HANDLER_IDX);

        this.indexBuffer = new HashIndexBuffer(this.indexSize);
        this.dataBuffer = new HashIndexDataBuffer(maxBlockLength, keyLength);

        init();

    }

    private int ensureIndexSizeIsPowerOfTwo(final int indexSize)
    {
        final int powerOfTwo = BitUtil.findNextPositivePowerOfTwo(indexSize);

        if (powerOfTwo != indexSize)
        {
            LOG.warn("Supplied index size {} is not a power of two. Using next power of two {} instead.", indexSize, powerOfTwo);
        }

        if (powerOfTwo > MAX_INDEX_SIZE)
        {
            LOG.warn("Index size {} greater then max index size. Using max index size {} instead.", powerOfTwo, MAX_INDEX_SIZE);
            return MAX_INDEX_SIZE;
        }
        else
        {
            return powerOfTwo;
        }
    }

    private void init()
    {
        final long blockOffset = this.dataBuffer.allocateNewBlock(0, 0);
        for (int idx = 0; idx < indexSize; idx++)
        {
            indexBuffer.setBlockOffset(idx, blockOffset);
        }
    }

    public void close()
    {
        if (isClosed.compareAndSet(false, true))
        {
            CloseHelper.quietClose(indexBuffer);
            CloseHelper.quietClose(dataBuffer);
        }
    }

    @Override
    protected void finalize() throws Throwable
    {
        if (!isClosed.get())
        {
            LOG.error(FINALIZER_WARNING);
        }

    }

    public void clear()
    {
        indexBuffer.clear();
        dataBuffer.clear();

        init();
    }

    private <K extends IndexKeyHandler> K createKeyHandlerInstance(int keyLength)
    {
        final K keyHandler = createInstance(KEY_HANDLER_IDX);
        keyHandler.setKeyLength(keyLength);
        return keyHandler;
    }

    @SuppressWarnings("unchecked")
    private <T> T createInstance(int index)
    {
        Class<T> tClass = null;
        try
        {
            tClass = (Class<T>) ((ParameterizedType) this.getClass()
                                                            .getGenericSuperclass()).getActualTypeArguments()[index];
            return tClass.newInstance();
        }
        catch (InstantiationException | IllegalAccessException e)
        {
            throw new RuntimeException("Could not instantiate " + tClass, e);
        }
    }


    public int blockCount()
    {
        return dataBuffer.getBlockCount();
    }

    protected boolean put()
    {
        final int keyHashCode = keyHandler.keyHashCode();
        final int blockId = keyHashCode & mask;

        boolean isUpdated = false;
        boolean isPut = false;
        boolean scanForKey = true;

        while (!isPut && !isUpdated)
        {
            final long blockOffset = indexBuffer.getBlockOffset(blockId);

            if (scanForKey)
            {
                final int blockFillCount = dataBuffer.getBlockFillCount(blockOffset);

                int recordOffset = BLOCK_DATA_OFFSET;
                int recordsVisited = 0;
                boolean keyFound = false;

                while (!keyFound && recordsVisited < blockFillCount)
                {
                    keyFound = dataBuffer.keyEquals(keyHandler, blockOffset, recordOffset);

                    if (keyFound)
                    {
                        isUpdated = dataBuffer.updateValue(valueHandler, blockOffset, recordOffset);
                    }

                    recordOffset += dataBuffer.getRecordLength(blockOffset, recordOffset);
                    recordsVisited++;
                }

                scanForKey = keyFound;

                if (keyFound && !isUpdated)
                {
                    // key found but could not be updated since length of new value is greater than length of old value
                    // and block is filled. Need to split to make room
                    splitBlock(blockOffset);
                }
            }
            else
            {
                isPut = dataBuffer.addRecord(blockOffset, keyHandler, valueHandler);

                if (!isPut)
                {
                    splitBlock(blockOffset);
                }
            }
        }

        return isUpdated;
    }

    protected boolean get()
    {
        final int keyHashCode = keyHandler.keyHashCode();
        final int blockId = keyHashCode & mask;
        final long blockOffset = indexBuffer.getBlockOffset(blockId);

        final int blockFillCount = dataBuffer.getBlockFillCount(blockOffset);
        int recordOffset = BLOCK_DATA_OFFSET;
        int recordsVisited = 0;
        boolean keyFound = false;

        while (!keyFound && recordsVisited < blockFillCount)
        {
            keyFound = dataBuffer.keyEquals(keyHandler, blockOffset, recordOffset);

            if (keyFound)
            {
                dataBuffer.readValue(valueHandler, blockOffset, recordOffset);
            }

            recordOffset += dataBuffer.getRecordLength(blockOffset, recordOffset);
            recordsVisited++;
        }

        return keyFound;
    }

    protected boolean remove()
    {
        final int keyHashCode = keyHandler.keyHashCode();
        final int blockId = keyHashCode & mask;
        final long blockOffset = indexBuffer.getBlockOffset(blockId);

        final int blockFillCount = dataBuffer.getBlockFillCount(blockOffset);
        int recordOffset = BLOCK_DATA_OFFSET;
        int recordsVisited = 0;
        boolean keyFound = false;

        while (!keyFound && recordsVisited < blockFillCount)
        {
            keyFound = dataBuffer.keyEquals(keyHandler, blockOffset, recordOffset);

            if (keyFound)
            {
                dataBuffer.readValue(valueHandler, blockOffset, recordOffset);
                dataBuffer.removeRecord(blockOffset, recordOffset);
            }

            recordOffset += dataBuffer.getRecordLength(blockOffset, recordOffset);
            recordsVisited++;
        }

        return keyFound;
    }

    /**
     * splits a block performing the index update and relocation and compaction of records.
     */
    private void splitBlock(long filledBlockOffset)
    {
        final int filledBlockId = dataBuffer.getBlockId(filledBlockOffset);
        final int blockDepth = dataBuffer.getBlockDepth(filledBlockOffset);

        // calculate new ids and depths
        final int newBlockId = 1 << blockDepth | filledBlockId;
        final int newBlockDepth = blockDepth + 1;

        if (newBlockId >= indexSize)
        {
            // TODO: implement overflow!
            throw new RuntimeException("Index Full. Cannot create new block with id " + newBlockId);
        }

        // update filled block depth
        dataBuffer.setBlockDepth(filledBlockOffset, newBlockDepth);

        // create new block
        final long newBlockOffset = dataBuffer.allocateNewBlock(newBlockId, newBlockDepth);

        // distribute entries into correct blocks
        distributeEntries(filledBlockOffset, newBlockOffset, blockDepth);

        // update index
        final int indexDiff = 1 << newBlockDepth;
        for (int i = newBlockId; i < indexSize; i += indexDiff)
        {
            indexBuffer.setBlockOffset(i, newBlockOffset);
        }
    }

    private void distributeEntries(long filledBlockOffset, long newBlockOffset, int blockDepth)
    {
        final int blockFillCount = dataBuffer.getBlockFillCount(filledBlockOffset);
        final int splitMask = 1 << blockDepth;

        int recordOffset = BLOCK_DATA_OFFSET;
        int recordsVisited = 0;

        while (recordsVisited < blockFillCount)
        {
            final int recordLength = dataBuffer.getRecordLength(filledBlockOffset, recordOffset);

            dataBuffer.readKey(splitKeyHandler, filledBlockOffset, recordOffset);
            final int keyHashCode = splitKeyHandler.keyHashCode();

            if ((keyHashCode & splitMask) == splitMask)
            {
                dataBuffer.relocateRecord(filledBlockOffset, recordOffset, recordLength, newBlockOffset);
            }
            else
            {
                recordOffset += recordLength;
            }

            recordsVisited++;
        }
    }

    public HashIndexDataBuffer getDataBuffer()
    {
        return dataBuffer;
    }

    public HashIndexBuffer getIndexBuffer()
    {
        return indexBuffer;
    }
}
